#!/usr/bin/env python3
"""
Cloud Services Detector - D√©tection et analyse de tous les services cloud
D√©tecte iCloud, OneDrive, Google Drive, Dropbox, Box, etc.
"""

import os
import sys
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
import json

class CloudServicesDetector:
    def __init__(self, home_path=None):
        self.home_path = Path(home_path) if home_path else Path.home()
        self.cloud_services = {}
        self.optimization_opportunities = []
        
        # D√©finition des services cloud √† d√©tecter
        self.cloud_definitions = {
            'iCloud Drive': {
                'paths': [
                    'Library/Mobile Documents/com~apple~CloudDocs',
                    'iCloud Drive (Archive)',
                    'Library/Mobile Documents'
                ],
                'indicators': ['.icloud', 'com~apple~'],
                'processes': ['bird', 'cloudd'],
                'optimization_strategy': 'apple_optimized'
            },
            'Google Drive': {
                'paths': [
                    'Library/CloudStorage/GoogleDrive-*',
                    'Google Drive',
                    'GoogleDrive'
                ],
                'indicators': ['.tmp', '.gdownload', '.gdoc', '.gsheet'],
                'processes': ['Google Drive'],
                'optimization_strategy': 'google_optimized'
            },
            'OneDrive': {
                'paths': [
                    'Library/CloudStorage/OneDrive-*',
                    'OneDrive',
                    'OneDrive - *'
                ],
                'indicators': ['.tmp', '~$', '.lock'],
                'processes': ['OneDrive', 'Microsoft OneDrive'],
                'optimization_strategy': 'microsoft_optimized'
            },
            'Dropbox': {
                'paths': [
                    'Dropbox',
                    'Dropbox (Personal)',
                    'Dropbox (Business)'
                ],
                'indicators': ['.dropbox', '.dropbox.cache'],
                'processes': ['Dropbox'],
                'optimization_strategy': 'dropbox_optimized'
            },
            'Box': {
                'paths': [
                    'Box',
                    'Box Sync'
                ],
                'indicators': ['.boxsync'],
                'processes': ['Box'],
                'optimization_strategy': 'box_optimized'
            },
            'pCloud': {
                'paths': [
                    'pCloudDrive',
                    'pCloud'
                ],
                'indicators': ['.pcloud'],
                'processes': ['pCloud'],
                'optimization_strategy': 'generic_cloud'
            },
            'Mega': {
                'paths': [
                    'MEGAsync',
                    'Mega'
                ],
                'indicators': ['.mega'],
                'processes': ['MEGAsync'],
                'optimization_strategy': 'generic_cloud'
            }
        }
        
    def detect_all_cloud_services(self):
        """D√©tecte tous les services cloud pr√©sents"""
        print("‚òÅÔ∏è  D√âTECTION DES SERVICES CLOUD")
        print("=" * 40)
        
        for service_name, config in self.cloud_definitions.items():
            service_info = self.detect_service(service_name, config)
            if service_info['detected']:
                self.cloud_services[service_name] = service_info
                
        if not self.cloud_services:
            print("‚úÖ Aucun service cloud d√©tect√©")
            return False
            
        # Analyser les opportunit√©s d'optimisation
        self.analyze_optimization_opportunities()
        return True
        
    def detect_service(self, service_name, config):
        """D√©tecte un service cloud sp√©cifique"""
        service_info = {
            'detected': False,
            'paths': [],
            'total_size': 0,
            'file_count': 0,
            'sync_active': False,
            'optimization_potential': 0,
            'issues': [],
            'strategy': config['optimization_strategy']
        }
        
        # 1. Rechercher les chemins
        detected_paths = self.find_service_paths(config['paths'])
        if not detected_paths:
            return service_info
            
        service_info['detected'] = True
        service_info['paths'] = detected_paths
        
        print(f"\n‚òÅÔ∏è  {service_name} d√©tect√©:")
        
        # 2. Analyser chaque chemin trouv√©
        for path in detected_paths:
            path_info = self.analyze_cloud_path(path, config)
            service_info['total_size'] += path_info['size']
            service_info['file_count'] += path_info['file_count']
            service_info['issues'].extend(path_info['issues'])
            
            if path_info['sync_active']:
                service_info['sync_active'] = True
                
            print(f"  üìÅ {path}")
            print(f"     üíæ Taille: {self.format_size(path_info['size'])}")
            print(f"     üìÑ Fichiers: {path_info['file_count']}")
            
            if path_info['issues']:
                print(f"     ‚ö†Ô∏è  Probl√®mes: {len(path_info['issues'])}")
                for issue in path_info['issues'][:3]:
                    print(f"        ‚Ä¢ {issue}")
                    
        # 3. V√©rifier les processus actifs
        if self.check_service_processes(config['processes']):
            service_info['sync_active'] = True
            print(f"  üîÑ Processus de sync actif")
        else:
            print(f"  ‚úÖ Pas de sync active")
            
        # 4. Calculer le potentiel d'optimisation
        service_info['optimization_potential'] = self.calculate_optimization_potential(service_info)
        print(f"  üìä Potentiel d'optimisation: {service_info['optimization_potential']}%")
        
        return service_info
        
    def find_service_paths(self, path_patterns):
        """Trouve les chemins d'un service cloud"""
        found_paths = []
        
        for pattern in path_patterns:
            if '*' in pattern:
                # Pattern avec wildcard
                parent_dir = self.home_path / Path(pattern).parent
                if parent_dir.exists():
                    pattern_name = Path(pattern).name.replace('*', '')
                    for item in parent_dir.iterdir():
                        if pattern_name in item.name and item.is_dir():
                            found_paths.append(str(item))
            else:
                # Chemin direct
                full_path = self.home_path / pattern
                if full_path.exists():
                    found_paths.append(str(full_path))
                    
        return found_paths
        
    def analyze_cloud_path(self, cloud_path, config):
        """Analyse un chemin cloud sp√©cifique"""
        path_info = {
            'size': 0,
            'file_count': 0,
            'sync_active': False,
            'issues': []
        }
        
        cloud_dir = Path(cloud_path)
        
        try:
            # Calcul rapide de la taille avec du
            result = subprocess.run(['du', '-sb', str(cloud_dir)], 
                                  capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                path_info['size'] = int(result.stdout.split()[0])
        except:
            pass
            
        # Comptage des fichiers (√©chantillon)
        try:
            file_count = 0
            sync_files = 0
            
            for root, dirs, files in os.walk(cloud_dir):
                # Limiter la profondeur pour la performance
                level = len(Path(root).relative_to(cloud_dir).parts)
                if level > 3:
                    dirs.clear()
                    continue
                    
                file_count += len(files)
                
                # D√©tecter les indicateurs de sync
                for file in files:
                    for indicator in config['indicators']:
                        if indicator in file.lower():
                            sync_files += 1
                            path_info['sync_active'] = True
                            
                if file_count > 10000:  # Limiter pour la performance
                    break
                    
            path_info['file_count'] = file_count
            
            if sync_files > 0:
                path_info['issues'].append(f"{sync_files} fichiers de sync d√©tect√©s")
                
        except Exception as e:
            path_info['issues'].append(f"Erreur d'analyse: {e}")
            
        # D√©tecter les probl√®mes sp√©cifiques
        self.detect_cloud_issues(cloud_dir, config, path_info)
        
        return path_info
        
    def detect_cloud_issues(self, cloud_dir, config, path_info):
        """D√©tecte les probl√®mes sp√©cifiques √† un service cloud"""
        
        # Probl√®mes communs
        try:
            # Fichiers tr√®s volumineux non adapt√©s au cloud
            large_files = []
            for root, dirs, files in os.walk(cloud_dir):
                level = len(Path(root).relative_to(cloud_dir).parts)
                if level > 2:
                    dirs.clear()
                    continue
                    
                for file in files[:100]:  # Limiter l'√©chantillon
                    file_path = Path(root) / file
                    try:
                        if file_path.stat().st_size > 1024*1024*1024:  # > 1GB
                            large_files.append(file)
                    except:
                        continue
                        
                if len(large_files) >= 10:
                    break
                    
            if large_files:
                path_info['issues'].append(f"{len(large_files)} fichiers > 1GB")
                
            # Doublons potentiels
            duplicates = self.detect_cloud_duplicates(cloud_dir)
            if duplicates > 0:
                path_info['issues'].append(f"{duplicates} doublons potentiels")
                
            # Fichiers anciens non utilis√©s
            old_files = self.detect_old_unused_files(cloud_dir)
            if old_files > 0:
                path_info['issues'].append(f"{old_files} fichiers anciens (>1 an)")
                
        except Exception as e:
            path_info['issues'].append(f"Erreur d√©tection probl√®mes: {e}")
            
    def detect_cloud_duplicates(self, cloud_dir):
        """D√©tecte les doublons dans un dossier cloud"""
        duplicates = 0
        seen_names = set()
        
        try:
            for root, dirs, files in os.walk(cloud_dir):
                level = len(Path(root).relative_to(cloud_dir).parts)
                if level > 2:
                    dirs.clear()
                    continue
                    
                for file in files[:200]:  # √âchantillon
                    base_name = Path(file).stem.lower()
                    
                    # Patterns de doublons
                    if any(pattern in base_name for pattern in [
                        'copy', '(1)', '(2)', 'duplicate', 'backup'
                    ]):
                        duplicates += 1
                    elif base_name in seen_names:
                        duplicates += 1
                    else:
                        seen_names.add(base_name)
                        
        except:
            pass
            
        return duplicates
        
    def detect_old_unused_files(self, cloud_dir):
        """D√©tecte les fichiers anciens non utilis√©s"""
        old_files = 0
        one_year_ago = datetime.now() - timedelta(days=365)
        
        try:
            for root, dirs, files in os.walk(cloud_dir):
                level = len(Path(root).relative_to(cloud_dir).parts)
                if level > 2:
                    dirs.clear()
                    continue
                    
                for file in files[:100]:  # √âchantillon
                    file_path = Path(root) / file
                    try:
                        mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                        if mtime < one_year_ago:
                            old_files += 1
                    except:
                        continue
                        
        except:
            pass
            
        return old_files
        
    def check_service_processes(self, process_names):
        """V√©rifie si des processus du service sont actifs"""
        try:
            result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
            processes = result.stdout.lower()
            
            for process_name in process_names:
                if process_name.lower() in processes:
                    return True
                    
        except:
            pass
            
        return False
        
    def calculate_optimization_potential(self, service_info):
        """Calcule le potentiel d'optimisation d'un service"""
        potential = 0
        
        # Plus de probl√®mes = plus de potentiel
        potential += min(50, len(service_info['issues']) * 10)
        
        # Gros volume = plus de potentiel
        if service_info['total_size'] > 10 * 1024**3:  # > 10GB
            potential += 30
        elif service_info['total_size'] > 1 * 1024**3:  # > 1GB
            potential += 20
            
        # Beaucoup de fichiers = potentiel de doublons
        if service_info['file_count'] > 10000:
            potential += 20
        elif service_info['file_count'] > 1000:
            potential += 10
            
        return min(100, potential)
        
    def analyze_optimization_opportunities(self):
        """Analyse les opportunit√©s d'optimisation globales"""
        print(f"\nüí° OPPORTUNIT√âS D'OPTIMISATION")
        print("=" * 35)
        
        total_cloud_size = 0
        total_issues = 0
        
        for service_name, info in self.cloud_services.items():
            total_cloud_size += info['total_size']
            total_issues += len(info['issues'])
            
            if info['optimization_potential'] > 50:
                opportunity = {
                    'service': service_name,
                    'potential': info['optimization_potential'],
                    'strategy': info['strategy'],
                    'size': info['total_size'],
                    'issues': info['issues']
                }
                self.optimization_opportunities.append(opportunity)
                
        print(f"üìä Total espace cloud: {self.format_size(total_cloud_size)}")
        print(f"‚ö†Ô∏è  Total probl√®mes d√©tect√©s: {total_issues}")
        print(f"üéØ Services optimisables: {len(self.optimization_opportunities)}")
        
        # Proposer des strat√©gies d'optimisation
        self.generate_optimization_strategies()
        
    def generate_optimization_strategies(self):
        """G√©n√®re des strat√©gies d'optimisation sp√©cifiques"""
        print(f"\nüéØ STRAT√âGIES D'OPTIMISATION RECOMMAND√âES")
        print("=" * 45)
        
        if not self.optimization_opportunities:
            print("‚úÖ Aucune optimisation majeure n√©cessaire")
            return
            
        for opportunity in sorted(self.optimization_opportunities, 
                                key=lambda x: x['potential'], reverse=True):
            
            print(f"\n‚òÅÔ∏è  {opportunity['service']} ({opportunity['potential']}% potentiel)")
            print(f"   üíæ Taille: {self.format_size(opportunity['size'])}")
            
            strategy = self.get_optimization_strategy(opportunity['strategy'])
            for action in strategy:
                print(f"   {action}")
                
    def get_optimization_strategy(self, strategy_type):
        """Retourne les actions pour une strat√©gie d'optimisation"""
        strategies = {
            'apple_optimized': [
                "üîÑ Optimiser le stockage iCloud dans Pr√©f√©rences Syst√®me",
                "üì± Activer 'Optimiser le stockage Mac' pour les Photos",
                "üóÇÔ∏è  D√©placer les gros fichiers vers 'iCloud Drive seulement'",
                "üßπ Vider la corbeille iCloud Drive",
                "üìã Archiver les anciens documents"
            ],
            'google_optimized': [
                "üîÑ Utiliser 'Streaming files' au lieu de 'Mirror files'",
                "üìÅ Archiver les anciens Google Docs/Sheets",
                "üóëÔ∏è  Nettoyer la corbeille Google Drive",
                "üì∏ Compresser les photos avec Google Photos",
                "üîó Convertir les gros fichiers en liens partag√©s"
            ],
            'microsoft_optimized': [
                "‚òÅÔ∏è  Activer 'Files On-Demand' dans OneDrive",
                "üìÅ D√©placer les gros fichiers vers OneDrive Archive",
                "üóëÔ∏è  Vider la corbeille OneDrive",
                "üìã Utiliser OneDrive Personal Vault pour les documents sensibles",
                "üîÑ Synchroniser seulement les dossiers essentiels"
            ],
            'dropbox_optimized': [
                "üíß Activer 'Smart Sync' pour les gros dossiers",
                "üóÇÔ∏è  Utiliser Dropbox Paper au lieu de fichiers Word",
                "üóëÔ∏è  Nettoyer les anciennes versions de fichiers",
                "üì¶ Archiver les projets termin√©s",
                "üîó Utiliser les liens partag√©s pour les gros fichiers"
            ],
            'box_optimized': [
                "üì¶ Activer Box Drive pour optimiser l'espace local",
                "üóÇÔ∏è  Organiser en dossiers par projet/client",
                "üóëÔ∏è  Nettoyer les anciennes versions",
                "üîÑ Synchroniser seulement les dossiers actifs"
            ],
            'generic_cloud': [
                "üíæ Configurer la synchronisation s√©lective",
                "üìÅ Organiser en structure de dossiers claire",
                "üóëÔ∏è  Nettoyer les fichiers temporaires",
                "üîÑ V√©rifier les param√®tres de synchronisation"
            ]
        }
        
        return strategies.get(strategy_type, strategies['generic_cloud'])
        
    def generate_optimization_commands(self):
        """G√©n√®re les commandes d'optimisation pour SmartOptimizer"""
        print(f"\nüîß COMMANDES D'OPTIMISATION SMARTOPTIMIZER")
        print("=" * 45)
        
        for service_name, info in self.cloud_services.items():
            if info['optimization_potential'] > 30:
                for path in info['paths']:
                    print(f"\n# Optimiser {service_name}")
                    print(f"python3 src/optimizers/cloud_optimizer.py \"{path}\"")
                    print(f"python3 src/reorganizers/smart_reorganizer.py \"{path}\"")
                    
    def format_size(self, size_bytes):
        """Formate une taille en bytes"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} PB"

def main():
    if len(sys.argv) > 1:
        home_path = sys.argv[1]
    else:
        home_path = None
        
    detector = CloudServicesDetector(home_path)
    
    if detector.detect_all_cloud_services():
        detector.generate_optimization_commands()
        
        print(f"\n‚úÖ D√©tection termin√©e")
        print(f"   Services d√©tect√©s: {len(detector.cloud_services)}")
        print(f"   Opportunit√©s d'optimisation: {len(detector.optimization_opportunities)}")
    else:
        print("‚ÑπÔ∏è  Aucun service cloud d√©tect√© √† optimiser")

if __name__ == "__main__":
    main()