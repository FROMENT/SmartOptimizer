#!/usr/bin/env python3
"""
Cloud Optimizer - Optimiseur spÃ©cialisÃ© pour les services cloud
Optimise iCloud, OneDrive, Google Drive avec stratÃ©gies spÃ©cifiques
"""

import os
import sys
import shutil
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
import subprocess
import json

class CloudOptimizer:
    def __init__(self, cloud_path):
        self.cloud_path = Path(cloud_path)
        self.cloud_service = self.detect_cloud_service()
        self.backup_dir = Path.home() / "SmartOptimizer_Backups" / "cloud_optimization" / datetime.now().strftime('%Y%m%d_%H%M%S')
        self.simulation_mode = True
        self.stats = {
            'files_analyzed': 0,
            'duplicates_found': 0,
            'large_files_found': 0,
            'old_files_found': 0,
            'space_recoverable': 0,
            'optimization_actions': []
        }
        
    def detect_cloud_service(self):
        """DÃ©tecte le type de service cloud"""
        path_str = str(self.cloud_path).lower()
        
        if 'icloud' in path_str or 'mobile documents' in path_str:
            return 'icloud'
        elif 'google' in path_str or 'googledrive' in path_str:
            return 'google_drive'
        elif 'onedrive' in path_str:
            return 'onedrive'
        elif 'dropbox' in path_str:
            return 'dropbox'
        elif 'box' in path_str:
            return 'box'
        else:
            return 'generic'
            
    def optimize_cloud_storage(self):
        """Optimise le stockage cloud avec stratÃ©gies spÃ©cifiques"""
        print(f"â˜ï¸  OPTIMISATION CLOUD: {self.cloud_service.upper()}")
        print(f"ğŸ“ Chemin: {self.cloud_path}")
        print("=" * 60)
        
        if not self.cloud_path.exists():
            print(f"âŒ Chemin cloud inexistant: {self.cloud_path}")
            return False
            
        # CrÃ©er le rÃ©pertoire de backup
        if not self.simulation_mode:
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
        # 1. Analyse initiale
        self.analyze_cloud_content()
        
        # 2. Optimisations spÃ©cifiques au service
        self.apply_service_specific_optimizations()
        
        # 3. Optimisations gÃ©nÃ©riques
        self.apply_generic_optimizations()
        
        # 4. Rapport final
        self.generate_optimization_report()
        
        return True
        
    def analyze_cloud_content(self):
        """Analyse le contenu du dossier cloud"""
        print("ğŸ” Analyse du contenu cloud...")
        
        duplicates = {}
        large_files = []
        old_files = []
        
        for root, dirs, files in os.walk(self.cloud_path):
            # Ignorer les dossiers systÃ¨me
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['System', 'Trash']]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = Path(root) / file
                self.stats['files_analyzed'] += 1
                
                try:
                    stat = file_path.stat()
                    size = stat.st_size
                    mtime = datetime.fromtimestamp(stat.st_mtime)
                    
                    # DÃ©tecter les gros fichiers (>100MB)
                    if size > 100 * 1024 * 1024:
                        large_files.append({
                            'path': file_path,
                            'size': size,
                            'modified': mtime
                        })
                        
                    # DÃ©tecter les vieux fichiers (>2 ans)
                    if mtime < datetime.now() - timedelta(days=730):
                        old_files.append({
                            'path': file_path,
                            'size': size,
                            'modified': mtime
                        })
                        
                    # DÃ©tecter les doublons potentiels
                    if size < 50 * 1024 * 1024:  # Seulement pour fichiers <50MB
                        file_hash = self.calculate_file_hash(file_path)
                        if file_hash:
                            if file_hash not in duplicates:
                                duplicates[file_hash] = []
                            duplicates[file_hash].append(file_path)
                            
                except Exception as e:
                    continue
                    
        # Traiter les rÃ©sultats
        self.process_analysis_results(duplicates, large_files, old_files)
        
    def calculate_file_hash(self, file_path):
        """Calcule le hash MD5 d'un fichier (pour les petits fichiers)"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                chunk = f.read(8192)  # Lire seulement le dÃ©but pour les gros fichiers
                if chunk:
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()[:16]  # Hash court
        except:
            return None
            
    def process_analysis_results(self, duplicates, large_files, old_files):
        """Traite les rÃ©sultats de l'analyse"""
        
        # Doublons
        real_duplicates = {k: v for k, v in duplicates.items() if len(v) > 1}
        self.stats['duplicates_found'] = len(real_duplicates)
        
        if real_duplicates:
            print(f"  ğŸ”„ {len(real_duplicates)} groupes de doublons trouvÃ©s")
            for file_hash, files in list(real_duplicates.items())[:5]:
                print(f"     â€¢ {len(files)} copies de {files[0].name}")
                
        # Gros fichiers
        self.stats['large_files_found'] = len(large_files)
        if large_files:
            print(f"  ğŸ“¦ {len(large_files)} fichiers volumineux (>100MB)")
            for large_file in large_files[:5]:
                size_mb = large_file['size'] / (1024 * 1024)
                print(f"     â€¢ {large_file['path'].name} ({size_mb:.1f}MB)")
                
        # Vieux fichiers
        self.stats['old_files_found'] = len(old_files)
        if old_files:
            print(f"  ğŸ“… {len(old_files)} fichiers anciens (>2 ans)")
            
        # Stocker pour optimisation
        self.duplicates = real_duplicates
        self.large_files = large_files
        self.old_files = old_files
        
    def apply_service_specific_optimizations(self):
        """Applique les optimisations spÃ©cifiques au service cloud"""
        print(f"\nâš¡ Optimisations spÃ©cifiques {self.cloud_service}...")
        
        if self.cloud_service == 'icloud':
            self.optimize_icloud()
        elif self.cloud_service == 'google_drive':
            self.optimize_google_drive()
        elif self.cloud_service == 'onedrive':
            self.optimize_onedrive()
        elif self.cloud_service == 'dropbox':
            self.optimize_dropbox()
        else:
            self.optimize_generic_cloud()
            
    def optimize_icloud(self):
        """Optimisations spÃ©cifiques iCloud"""
        
        # 1. Organiser par type dans des dossiers appropriÃ©s
        self.organize_icloud_structure()
        
        # 2. Identifier les fichiers .icloud non tÃ©lÃ©chargÃ©s
        self.handle_icloud_placeholders()
        
        # 3. Optimiser les photos (si dossier Photos dÃ©tectÃ©)
        self.optimize_icloud_photos()
        
    def organize_icloud_structure(self):
        """Organise la structure iCloud Drive"""
        suggested_structure = {
            'Documents_Active': ['doc', 'docx', 'pdf', 'txt', 'pages'],
            'Spreadsheets': ['xls', 'xlsx', 'numbers', 'csv'],
            'Presentations': ['ppt', 'pptx', 'key'],
            'Images_Graphics': ['jpg', 'png', 'gif', 'psd', 'ai'],
            'Archive_Old': []  # Pour les vieux fichiers
        }
        
        print("  ğŸ—‚ï¸  Organisation de la structure iCloud...")
        
        for folder_name, extensions in suggested_structure.items():
            folder_path = self.cloud_path / folder_name
            
            if extensions:  # Dossiers par type
                files_to_move = []
                for ext in extensions:
                    files_to_move.extend(self.cloud_path.glob(f"*.{ext}"))
                    files_to_move.extend(self.cloud_path.glob(f"*.{ext.upper()}"))
                    
                if files_to_move:
                    action = f"CrÃ©er {folder_name} et dÃ©placer {len(files_to_move)} fichiers {extensions}"
                    self.stats['optimization_actions'].append(action)
                    print(f"     ğŸ“ {action}")
                    
                    if not self.simulation_mode:
                        folder_path.mkdir(exist_ok=True)
                        for file_path in files_to_move:
                            try:
                                shutil.move(str(file_path), str(folder_path / file_path.name))
                            except:
                                continue
                                
    def handle_icloud_placeholders(self):
        """GÃ¨re les fichiers .icloud (placeholders)"""
        icloud_files = list(self.cloud_path.rglob("*.icloud"))
        
        if icloud_files:
            print(f"  â˜ï¸  {len(icloud_files)} fichiers iCloud non tÃ©lÃ©chargÃ©s")
            
            large_placeholders = []
            for placeholder in icloud_files:
                original_name = placeholder.name.replace('.icloud', '')
                # Estimer la taille depuis le nom si possible
                large_placeholders.append(placeholder)
                
            if large_placeholders:
                action = f"Identifier {len(large_placeholders)} placeholders Ã  tÃ©lÃ©charger ou archiver"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ“¥ {action}")
                
    def optimize_icloud_photos(self):
        """Optimise les photos iCloud"""
        photos_folders = ['Photos', 'Pictures', 'Images']
        
        for folder_name in photos_folders:
            photos_path = self.cloud_path / folder_name
            if photos_path.exists():
                print(f"  ğŸ“¸ Optimisation du dossier {folder_name}...")
                
                # DÃ©tecter les formats inefficaces
                inefficient_formats = list(photos_path.glob("*.bmp")) + list(photos_path.glob("*.tiff"))
                
                if inefficient_formats:
                    action = f"Convertir {len(inefficient_formats)} images vers JPEG pour Ã©conomiser l'espace"
                    self.stats['optimization_actions'].append(action)
                    print(f"     ğŸ”„ {action}")
                    
    def optimize_google_drive(self):
        """Optimisations spÃ©cifiques Google Drive"""
        
        # 1. Identifier les Google Docs natifs vs fichiers uploadÃ©s
        self.optimize_google_native_files()
        
        # 2. Organiser par projet/client
        self.organize_google_drive_structure()
        
        # 3. GÃ©rer les fichiers partagÃ©s
        self.optimize_google_shared_files()
        
    def optimize_google_native_files(self):
        """Optimise les fichiers Google natifs"""
        google_extensions = ['.gdoc', '.gsheet', '.gslides', '.gdraw']
        
        native_files = []
        for ext in google_extensions:
            native_files.extend(self.cloud_path.rglob(f"*{ext}"))
            
        if native_files:
            print(f"  ğŸ“ {len(native_files)} fichiers Google natifs (optimaux)")
            
        # Identifier les fichiers Word/Excel qui pourraient Ãªtre convertis
        convertible_files = list(self.cloud_path.rglob("*.docx")) + list(self.cloud_path.rglob("*.xlsx"))
        
        if convertible_files:
            action = f"Convertir {len(convertible_files)} fichiers Office en Google Docs pour Ã©conomiser l'espace"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ”„ {action}")
            
    def organize_google_drive_structure(self):
        """Organise la structure Google Drive"""
        suggested_structure = {
            'Active_Projects': [],
            'Shared_With_Me': [],
            'Archive_Completed': [],
            'Personal_Documents': []
        }
        
        print("  ğŸ—‚ï¸  Organisation Google Drive par projets...")
        
        # DÃ©tecter les dossiers projet (contenant beaucoup de fichiers)
        project_folders = []
        for item in self.cloud_path.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                file_count = len(list(item.iterdir())[:100])  # Ã‰chantillon
                if file_count > 10:
                    project_folders.append(item)
                    
        if project_folders:
            action = f"Organiser {len(project_folders)} dossiers projets dans une structure claire"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ“ {action}")
            
    def optimize_google_shared_files(self):
        """Optimise les fichiers partagÃ©s Google"""
        # Note: DÃ©tection basique car les mÃ©tadonnÃ©es de partage ne sont pas accessibles via filesystem
        print("  ğŸ”— Recommandation: VÃ©rifier les fichiers partagÃ©s dans l'interface Google Drive")
        
        action = "RÃ©viser les permissions de partage et nettoyer les anciens partages"
        self.stats['optimization_actions'].append(action)
        
    def optimize_onedrive(self):
        """Optimisations spÃ©cifiques OneDrive"""
        
        # 1. Organiser par type Office
        self.optimize_office_files()
        
        # 2. GÃ©rer les fichiers volumineux
        self.optimize_onedrive_large_files()
        
        # 3. Structure professionnelle
        self.organize_onedrive_business_structure()
        
    def optimize_office_files(self):
        """Optimise les fichiers Office dans OneDrive"""
        office_files = {
            'Word': list(self.cloud_path.rglob("*.docx")) + list(self.cloud_path.rglob("*.doc")),
            'Excel': list(self.cloud_path.rglob("*.xlsx")) + list(self.cloud_path.rglob("*.xls")),
            'PowerPoint': list(self.cloud_path.rglob("*.pptx")) + list(self.cloud_path.rglob("*.ppt"))
        }
        
        for app_name, files in office_files.items():
            if files:
                print(f"  ğŸ“Š {len(files)} fichiers {app_name}")
                
                # Identifier les versions temporaires et de rÃ©cupÃ©ration
                temp_files = [f for f in files if '~$' in f.name or 'AutoRecovery' in f.name]
                
                if temp_files:
                    action = f"Nettoyer {len(temp_files)} fichiers temporaires {app_name}"
                    self.stats['optimization_actions'].append(action)
                    print(f"     ğŸ§¹ {action}")
                    
    def optimize_onedrive_large_files(self):
        """Optimise les gros fichiers OneDrive"""
        if self.large_files:
            print(f"  ğŸ“¦ Gestion des {len(self.large_files)} gros fichiers...")
            
            # CatÃ©goriser par type
            videos = [f for f in self.large_files if f['path'].suffix.lower() in ['.mp4', '.avi', '.mov']]
            archives = [f for f in self.large_files if f['path'].suffix.lower() in ['.zip', '.rar', '.7z']]
            
            if videos:
                action = f"ConsidÃ©rer compression ou archivage de {len(videos)} vidÃ©os volumineuses"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ¬ {action}")
                
            if archives:
                action = f"RÃ©viser la nÃ©cessitÃ© de {len(archives)} archives volumineuses"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ“¦ {action}")
                
    def organize_onedrive_business_structure(self):
        """Organise OneDrive avec une structure professionnelle"""
        business_structure = {
            'Current_Projects': [],
            'Client_Documents': [],
            'Templates_Resources': [],
            'Archive_Completed': [],
            'Personal_Workspace': []
        }
        
        print("  ğŸ’¼ Organisation structure professionnelle...")
        
        # DÃ©tecter les fichiers qui sembleraient Ãªtre des templates
        potential_templates = []
        for file_path in self.cloud_path.rglob("*template*"):
            potential_templates.append(file_path)
        for file_path in self.cloud_path.rglob("*model*"):
            potential_templates.append(file_path)
            
        if potential_templates:
            action = f"Organiser {len(potential_templates)} templates dans un dossier dÃ©diÃ©"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ“‹ {action}")
            
    def optimize_dropbox(self):
        """Optimisations spÃ©cifiques Dropbox"""
        
        # 1. GÃ©rer les conflits de version
        self.resolve_dropbox_conflicts()
        
        # 2. Optimiser la structure par projet
        self.organize_dropbox_projects()
        
        # 3. GÃ©rer les fichiers partagÃ©s
        self.optimize_dropbox_sharing()
        
    def resolve_dropbox_conflicts(self):
        """RÃ©sout les conflits de version Dropbox"""
        conflict_files = list(self.cloud_path.rglob("* (Conflicted copy *"))
        conflict_files.extend(self.cloud_path.rglob("* (Case Conflict*)"))
        
        if conflict_files:
            print(f"  âš ï¸  {len(conflict_files)} conflits de version dÃ©tectÃ©s")
            
            action = f"RÃ©soudre {len(conflict_files)} conflits de version Dropbox"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ”§ {action}")
            
            # Calculer l'espace rÃ©cupÃ©rable
            total_conflict_size = 0
            for conflict_file in conflict_files:
                try:
                    total_conflict_size += conflict_file.stat().st_size
                except:
                    continue
                    
            if total_conflict_size > 0:
                self.stats['space_recoverable'] += total_conflict_size
                print(f"     ğŸ’¾ Espace rÃ©cupÃ©rable: {self.format_size(total_conflict_size)}")
                
    def optimize_dropbox_projects(self):
        """Optimise l'organisation des projets Dropbox"""
        print("  ğŸ“ Organisation des projets Dropbox...")
        
        # DÃ©tecter les dossiers projet actifs vs anciens
        project_folders = []
        for item in self.cloud_path.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                # VÃ©rifier la date de derniÃ¨re modification
                try:
                    latest_mtime = max(f.stat().st_mtime for f in item.rglob("*") if f.is_file())
                    last_modified = datetime.fromtimestamp(latest_mtime)
                    
                    if last_modified < datetime.now() - timedelta(days=180):  # 6 mois
                        project_folders.append(('archive', item))
                    else:
                        project_folders.append(('active', item))
                except:
                    project_folders.append(('unknown', item))
                    
        archive_candidates = [p for status, p in project_folders if status == 'archive']
        
        if archive_candidates:
            action = f"Archiver {len(archive_candidates)} projets inactifs depuis >6 mois"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ“¦ {action}")
            
    def optimize_dropbox_sharing(self):
        """Optimise les fichiers partagÃ©s Dropbox"""
        # DÃ©tecter les gros fichiers qui pourraient Ãªtre des liens
        large_shared_candidates = [f for f in self.large_files if f['size'] > 500 * 1024 * 1024]  # >500MB
        
        if large_shared_candidates:
            action = f"Convertir {len(large_shared_candidates)} gros fichiers en liens partagÃ©s"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ”— {action}")
            
    def optimize_generic_cloud(self):
        """Optimisations gÃ©nÃ©riques pour services cloud inconnus"""
        print("  ğŸ”§ Optimisations gÃ©nÃ©riques...")
        
        # Organisation basique par type
        self.organize_generic_structure()
        
    def organize_generic_structure(self):
        """Organisation gÃ©nÃ©rique par type de fichier"""
        file_categories = {
            'Documents': ['pdf', 'doc', 'docx', 'txt', 'rtf'],
            'Spreadsheets': ['xls', 'xlsx', 'csv'],
            'Presentations': ['ppt', 'pptx'],
            'Images': ['jpg', 'jpeg', 'png', 'gif', 'bmp'],
            'Videos': ['mp4', 'avi', 'mov', 'mkv'],
            'Archives': ['zip', 'rar', '7z', 'tar']
        }
        
        for category, extensions in file_categories.items():
            files_in_category = []
            for ext in extensions:
                files_in_category.extend(self.cloud_path.glob(f"*.{ext}"))
                files_in_category.extend(self.cloud_path.glob(f"*.{ext.upper()}"))
                
            if files_in_category:
                action = f"Organiser {len(files_in_category)} fichiers dans le dossier {category}"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ“ {action}")
                
    def apply_generic_optimizations(self):
        """Applique les optimisations gÃ©nÃ©riques"""
        print("\nğŸ§¹ Optimisations gÃ©nÃ©riques...")
        
        # 1. Traiter les doublons
        self.handle_duplicates()
        
        # 2. GÃ©rer les vieux fichiers
        self.handle_old_files()
        
        # 3. Nettoyer les fichiers temporaires
        self.clean_temporary_files()
        
    def handle_duplicates(self):
        """GÃ¨re les fichiers dupliquÃ©s"""
        if hasattr(self, 'duplicates') and self.duplicates:
            print(f"  ğŸ”„ Traitement de {len(self.duplicates)} groupes de doublons...")
            
            total_recoverable = 0
            for file_hash, files in self.duplicates.items():
                if len(files) > 1:
                    # Garder le plus rÃ©cent, supprimer les autres
                    files_sorted = sorted(files, key=lambda f: f.stat().st_mtime, reverse=True)
                    best_file = files_sorted[0]
                    duplicates_to_remove = files_sorted[1:]
                    
                    for dup_file in duplicates_to_remove:
                        try:
                            file_size = dup_file.stat().st_size
                            total_recoverable += file_size
                            
                            if not self.simulation_mode:
                                # Backup puis suppression
                                backup_path = self.backup_dir / dup_file.name
                                shutil.copy2(dup_file, backup_path)
                                dup_file.unlink()
                                
                        except:
                            continue
                            
            if total_recoverable > 0:
                self.stats['space_recoverable'] += total_recoverable
                action = f"Supprimer doublons - Espace rÃ©cupÃ©rable: {self.format_size(total_recoverable)}"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ’¾ {action}")
                
    def handle_old_files(self):
        """GÃ¨re les vieux fichiers"""
        if hasattr(self, 'old_files') and self.old_files:
            print(f"  ğŸ“… Traitement de {len(self.old_files)} fichiers anciens...")
            
            # Proposer archivage plutÃ´t que suppression
            archive_folder = self.cloud_path / "Archive_Old_Files"
            
            total_old_size = sum(f['size'] for f in self.old_files)
            
            action = f"Archiver {len(self.old_files)} fichiers anciens ({self.format_size(total_old_size)})"
            self.stats['optimization_actions'].append(action)
            print(f"     ğŸ“¦ {action}")
            
            if not self.simulation_mode:
                archive_folder.mkdir(exist_ok=True)
                for old_file in self.old_files[:10]:  # Limiter pour la sÃ©curitÃ©
                    try:
                        shutil.move(str(old_file['path']), str(archive_folder / old_file['path'].name))
                    except:
                        continue
                        
    def clean_temporary_files(self):
        """Nettoie les fichiers temporaires"""
        temp_patterns = ['*.tmp', '*.temp', '~$*', '.DS_Store', 'Thumbs.db', '*.bak']
        
        temp_files = []
        for pattern in temp_patterns:
            temp_files.extend(self.cloud_path.rglob(pattern))
            
        if temp_files:
            print(f"  ğŸ—‘ï¸  {len(temp_files)} fichiers temporaires trouvÃ©s")
            
            total_temp_size = 0
            for temp_file in temp_files:
                try:
                    total_temp_size += temp_file.stat().st_size
                    
                    if not self.simulation_mode:
                        temp_file.unlink()
                        
                except:
                    continue
                    
            if total_temp_size > 0:
                self.stats['space_recoverable'] += total_temp_size
                action = f"Supprimer fichiers temporaires - Espace rÃ©cupÃ©rÃ©: {self.format_size(total_temp_size)}"
                self.stats['optimization_actions'].append(action)
                print(f"     ğŸ—‘ï¸  {action}")
                
    def generate_optimization_report(self):
        """GÃ©nÃ¨re le rapport d'optimisation"""
        print(f"\nğŸ“Š RAPPORT D'OPTIMISATION CLOUD")
        print("=" * 40)
        
        print(f"â˜ï¸  Service: {self.cloud_service.upper()}")
        print(f"ğŸ“ Chemin: {self.cloud_path}")
        print(f"ğŸ“„ Fichiers analysÃ©s: {self.stats['files_analyzed']}")
        print(f"ğŸ”„ Groupes de doublons: {self.stats['duplicates_found']}")
        print(f"ğŸ“¦ Fichiers volumineux: {self.stats['large_files_found']}")
        print(f"ğŸ“… Fichiers anciens: {self.stats['old_files_found']}")
        print(f"ğŸ’¾ Espace rÃ©cupÃ©rable: {self.format_size(self.stats['space_recoverable'])}")
        
        print(f"\nğŸ¯ ACTIONS D'OPTIMISATION ({len(self.stats['optimization_actions'])}):")
        for i, action in enumerate(self.stats['optimization_actions'], 1):
            print(f"  {i:2d}. {action}")
            
        if self.simulation_mode:
            print(f"\nâš ï¸  MODE SIMULATION - Aucune modification effectuÃ©e")
            print(f"   Pour appliquer les optimisations: modifier simulation_mode = False")
        else:
            print(f"\nâœ… Optimisations appliquÃ©es")
            print(f"   Sauvegarde: {self.backup_dir}")
            
    def format_size(self, size_bytes):
        """Formate une taille en bytes"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"

def main():
    if len(sys.argv) != 2:
        print("Usage: python3 cloud_optimizer.py <cloud_directory>")
        print("Examples:")
        print("  python3 cloud_optimizer.py ~/Library/Mobile\\ Documents/com~apple~CloudDocs")
        print("  python3 cloud_optimizer.py ~/OneDrive")
        print("  python3 cloud_optimizer.py ~/Dropbox")
        sys.exit(1)
        
    cloud_path = sys.argv[1]
    if not os.path.exists(cloud_path):
        print(f"âŒ RÃ©pertoire cloud inexistant: {cloud_path}")
        sys.exit(1)
        
    optimizer = CloudOptimizer(cloud_path)
    
    print("ğŸ”’ MODE SIMULATION ACTIVÃ‰")
    print("   Les optimisations seront simulÃ©es sans modifications rÃ©elles")
    print()
    
    if optimizer.optimize_cloud_storage():
        print(f"\nğŸ‰ Optimisation terminÃ©e!")
        if optimizer.stats['space_recoverable'] > 0:
            print(f"ğŸ’¾ Espace total rÃ©cupÃ©rable: {optimizer.format_size(optimizer.stats['space_recoverable'])}")
    else:
        print("âŒ Erreur durant l'optimisation")
        sys.exit(1)

if __name__ == "__main__":
    main()